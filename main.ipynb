{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import compare_anns\n",
    "import itertools\n",
    "\n",
    "#read the fasta file\n",
    "def read_fasta_file(filename):\n",
    "    \"\"\"\n",
    "    Reads the given FASTA file f and returns a dictionary of sequences.\n",
    "\n",
    "    Lines starting with ';' in the FASTA file are ignored.\n",
    "    \"\"\"\n",
    "    sequences_lines = {}\n",
    "    current_sequence_lines = None\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            line = line.strip()\n",
    "            if line.startswith(';') or not line:\n",
    "                continue\n",
    "            if line.startswith('>'):\n",
    "                sequence_name = line.lstrip('>')\n",
    "                current_sequence_lines = []\n",
    "                sequences_lines[sequence_name] = current_sequence_lines\n",
    "            else:\n",
    "                if current_sequence_lines is not None:\n",
    "                    current_sequence_lines.append(line)\n",
    "    sequences = {}\n",
    "    for name, lines in sequences_lines.items():\n",
    "        sequences[name] = ''.join(lines)\n",
    "    return sequences\n",
    "\n",
    "#translate from letters to indices\n",
    "def translate_observations_to_indices(obs):\n",
    "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    return [mapping[symbol] for symbol in obs]\n",
    "\n",
    "#translate from annotations to indices\n",
    "def translate_annotations_to_indices(obs):\n",
    "    mapping = {'N': 0, 'C': 7, 'R': 8}\n",
    "    return [mapping[symbol] for symbol in obs]\n",
    "\n",
    "data={}\n",
    "for i in np.arange(1,11):\n",
    "    temp={}\n",
    "    temp[f'genome{str(i)}'] = read_fasta_file(f'genome{str(i)}.fa')[f'genome{str(i)}']\n",
    "    data.update(temp)\n",
    "for i in np.arange(1,6):\n",
    "    temp={}\n",
    "    temp[f'true-ann{str(i)}'] = read_fasta_file(f'true-ann{str(i)}.fa')[f'true-ann{str(i)}']\n",
    "    data.update(temp)\n",
    "\n",
    "#load into data\n",
    "data2 = {}\n",
    "for i in np.arange(1,11):\n",
    "    temp={}\n",
    "    temp[f'genome{str(i)}'] = translate_observations_to_indices(read_fasta_file(f'genome{str(i)}.fa')[f'genome{str(i)}'])\n",
    "    data2.update(temp)\n",
    "for i in np.arange(1,6):\n",
    "    temp={}\n",
    "    temp[f'true-ann{str(i)}'] = translate_annotations_to_indices(read_fasta_file(f'true-ann{str(i)}.fa')[f'true-ann{str(i)}'])\n",
    "    data2.update(temp)\n",
    "#954265\n",
    "#809+809+639+639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group codons\n",
    "triplet_indices=[[0],[1],[2],[3]]\n",
    "triplet_indices+=[list(x) for x in itertools.product([0,1,2,3],repeat=3)]\n",
    "\n",
    "def group_codons(ann):\n",
    "    i=1\n",
    "    out=[0]\n",
    "    while i < len(ann):\n",
    "        if out[-1]==0 and ann[i]==0:\n",
    "            out.append(0)\n",
    "        elif (out[-1]==1 and ann[i]==7) or (out[-1]==2 and ann[i]==7) :\n",
    "            out.append(2)\n",
    "            i+=2\n",
    "        elif (out[-1]==4 and ann[i]==8)  or (out[-1]==5 and ann[i]==8) :\n",
    "            out.append(5)\n",
    "            i+=2\n",
    "        elif (out[-1]==0 and ann[i]==7) :\n",
    "            out.append(1)\n",
    "            i+=2\n",
    "        elif (out[-1]==0 and ann[i]==8) :\n",
    "            out.append(4)\n",
    "            i+=2\n",
    "        elif (out[-1]==2 and ann[i]==0) :\n",
    "            out[-1]=3\n",
    "            out.append(0)\n",
    "        elif (out[-1]==5 and ann[i]==0) :\n",
    "            out[-1]=6\n",
    "            out.append(0)\n",
    "        elif (out[-1]==2 and ann[i]==8) :\n",
    "            out[-1]=3\n",
    "            out.append(4)\n",
    "            i+=2\n",
    "        elif (out[-1]==5 and ann[i]==7) :\n",
    "            out[-1]=6\n",
    "            out.append(1)\n",
    "            i+=2\n",
    "        i+=1\n",
    "    return out\n",
    "\n",
    "data3=data2\n",
    "\n",
    "for i in np.arange(1,6):\n",
    "    data3[f\"true-ann{str(i)}\"]=group_codons(data3[f\"true-ann{str(i)}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hmm:\n",
    "    def __init__(self, init_probs, trans_probs, emission_probs):\n",
    "        self.init_probs = init_probs\n",
    "        self.trans_probs = trans_probs\n",
    "        self.emission_probs = emission_probs\n",
    "\n",
    "d=[1,3,3,3,3,3,3]\n",
    "\n",
    "def count_transitions_and_emissions_var(K, D, x, z):\n",
    "    \"\"\"\n",
    "    Returns a KxK matrix and a KxD matrix containing counts cf. above\n",
    "    \"\"\"\n",
    "    kxk=np.zeros((K,K))\n",
    "    kxd=np.zeros((K,D))\n",
    "    count=0\n",
    "    total=0\n",
    "    while total < len(x):\n",
    "        kxd[z[count]][triplet_indices.index(x[total:total+d[z[count]]])]+=1\n",
    "        total+=d[z[count]]\n",
    "        count+=1\n",
    "    for j in np.arange(len(z)-1):\n",
    "        kxk[z[j]][z[j+1]]+=1\n",
    "    return kxk,kxd\n",
    "\n",
    "def training_by_counting_var(K, D, x, z):\n",
    "    \"\"\"\n",
    "    Returns a HMM trained on x and z cf. training-by-counting.\n",
    "    \"\"\"\n",
    "    init_probs=np.zeros(K)\n",
    "    init_probs[z[0]]=1\n",
    "    trans_probs,emission_probs=count_transitions_and_emissions_var(K,D,x,z)\n",
    "    trans_probs/=np.sum(trans_probs,1).reshape(-1,1)\n",
    "    emission_probs/=np.sum(emission_probs,1).reshape(-1,1)\n",
    "    return hmm(init_probs,trans_probs,emission_probs)\n",
    "\n",
    "#count emission probs\n",
    "result=[]\n",
    "for i in np.arange(5):\n",
    "    four_test=np.delete(np.arange(5),[i])\n",
    "    four_genome=[]\n",
    "    four_ann=[]\n",
    "    for j in four_test:\n",
    "        four_genome.extend(data3[f\"genome{str(j+1)}\"])\n",
    "        four_ann.extend(data3[f\"true-ann{str(j+1)}\"])\n",
    "    result.append(training_by_counting_var(7,68,four_genome,four_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102425/567583556.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,0]=np.log(model.init_probs[i])+np.log(model.emission_probs[i,x[0]])\n",
      "/tmp/ipykernel_102425/567583556.py:18: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n",
      "/tmp/ipykernel_102425/567583556.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(0)\n",
      "/tmp/ipykernel_102425/567583556.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n",
      "/tmp/ipykernel_102425/567583556.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(0)\n",
      "/tmp/ipykernel_102425/567583556.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n"
     ]
    }
   ],
   "source": [
    "data4=data3\n",
    "\n",
    "def compute_w_log_var(model, x):\n",
    "    k = len(model.init_probs)\n",
    "    n = len(x)\n",
    "    w = np.zeros((k, n))\n",
    "    # Base case: fill out w[i][0] for i = 0..k-1\n",
    "    # ...\n",
    "    for i in np.arange(0,k):\n",
    "        w[i,0]=np.log(model.init_probs[i])+np.log(model.emission_probs[i,x[0]])\n",
    "    # Inductive case: fill out w[i][j] for i = 0..k, j = 0..n-1\n",
    "    # ...\n",
    "    j=1\n",
    "    for i in np.arange(0,k):\n",
    "        if i != 0:\n",
    "            w[i,j]=np.log(0)\n",
    "        else:\n",
    "            w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n",
    "    j=2\n",
    "    for i in np.arange(0,k):\n",
    "        if i in [2,3,5,6]:\n",
    "            w[i,j]=np.log(0)\n",
    "        else:\n",
    "            w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n",
    "    for j in np.arange(3,n):\n",
    "        for i in np.arange(k):\n",
    "            w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n",
    "    return w\n",
    "\n",
    "w=[]\n",
    "for i in np.arange(5):\n",
    "    w.append(compute_w_log_var(result[i],data4[f\"genome{str(i+1)}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102425/768606769.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  zstar.append(np.argmax(two+np.log(three)))\n"
     ]
    }
   ],
   "source": [
    "def backtrack_log_var(model, x, w):\n",
    "    n=len(x)\n",
    "    zstar=[]\n",
    "    total=n\n",
    "    zstar.append(np.argmax(w[:,total-1]))\n",
    "    total-=d[zstar[0]]\n",
    "    count=1\n",
    "    while total>0:\n",
    "        zstar.append(np.argmax(w[:,total-1]+np.log(np.array(model.trans_probs)[:,zstar[count-1]])))\n",
    "        total-=d[zstar[count]]\n",
    "        count+=1\n",
    "    zstar.reverse()\n",
    "    return zstar\n",
    "\n",
    "\n",
    "for i in np.arange(5):\n",
    "    data4[f\"pred-ann{str(i+1)}\"]=backtrack_log_var(result[i],data4[f\"genome{str(i+1)}\"],w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cs   (tp=708114, fp=134841, tn=288570, fn=19648): Sn = 0.9730, Sp = 0.8400, AC = 0.7154\n",
      "Rs   (tp=603493, fp=97775, tn=293270, fn=14948): Sn = 0.9758, Sp = 0.8606, AC = 0.7689\n",
      "Both (tp=1311607, fp=232616, tn=273622, fn=34596): Sn = 0.9743, Sp = 0.8494, AC = 0.6260\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def translate_indices_to_annotations(ann):\n",
    "    mapping = ['N', 'CCC', 'CCC', 'CCC', 'RRR', 'RRR', 'RRR']\n",
    "    return ''.join(mapping[idx] for idx in ann)\n",
    "\n",
    "def compute_accuracy(true_ann, pred_ann):\n",
    "    # Check annoation length\n",
    "    if len(true_ann) != len(pred_ann):\n",
    "        print(\"ERROR: The lengths of two predictions are different\")\n",
    "        print(\"Expected %d, but found %d\" % (len(true_ann), len(pred_ann)))  \n",
    "    else:\n",
    "        # Print stats\n",
    "        compare_anns.print_all(true_ann, pred_ann)\n",
    "\n",
    "accuracy=[]\n",
    "for i in np.arange(5):\n",
    "    accuracy.append(compute_accuracy(data[f\"true-ann{str(i+1)}\"],translate_indices_to_annotations(data4[f\"pred-ann{str(i+1)}\"])))\n",
    "\n",
    "best_model=np.argmax(accuracy)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102425/567583556.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,0]=np.log(model.init_probs[i])+np.log(model.emission_probs[i,x[0]])\n",
      "/tmp/ipykernel_102425/567583556.py:18: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n",
      "/tmp/ipykernel_102425/567583556.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(0)\n",
      "/tmp/ipykernel_102425/567583556.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n",
      "/tmp/ipykernel_102425/567583556.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(0)\n",
      "/tmp/ipykernel_102425/567583556.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "  w[i,j]=np.log(model.emission_probs[i,triplet_indices.index(x[j-d[i]+1:j+1])])+max(w[:,j-d[i]]+np.log(np.array(model.trans_probs)[:,i]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#write fasta file\n",
    "def write_fasta_file(filename,string):\n",
    "    f=open(f\"{filename}.fa\",\"w\")\n",
    "    f.write(f\">{filename}\\n{string}\\n\")\n",
    "    f.close()\n",
    "\n",
    "data5=data4\n",
    "for i in np.arange(6,11):\n",
    "    #decode using best model\n",
    "    data5[f\"pred-ann{str(i)}\"]=backtrack_log_var(result[best_model],data5[f\"genome{str(i)}\"],compute_w_log_var(result[best_model],data5[f\"genome{str(i)}\"]))\n",
    "    #write to file\n",
    "    write_fasta_file(f\"pred-ann{str(i)}\",translate_indices_to_annotations(data5[f\"pred-ann{str(i)}\"]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
